{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lhuang37\\.conda\\envs\\ocp-models\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "ERROR:root:Invalid setup for SCN. Either the e3nn library or Jd.pt is missing.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Copyright (c) Facebook, Inc. and its affiliates.\n",
    "This source code is licensed under the MIT license found in the\n",
    "LICENSE file in the root directory of this source tree.\n",
    "\"\"\"\n",
    "\n",
    "import logging\n",
    "import os\n",
    "from typing import Optional\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.nn import radius_graph\n",
    "from torch_scatter import scatter, segment_coo\n",
    "\n",
    "from ocpmodels.common.registry import registry\n",
    "from ocpmodels.common.utils import (\n",
    "    compute_neighbors,\n",
    "    conditional_grad,\n",
    "    get_max_neighbors_mask,\n",
    "    get_pbc_distances,\n",
    "    radius_graph_pbc,\n",
    "    scatter_det\n",
    "    \n",
    ")\n",
    "from ocpmodels.datasets import LmdbDataset\n",
    "from ocpmodels.modules.scaling.compat import load_scales_compat\n",
    "\n",
    "from ocpmodels.models.gemnet_oc.initializers import get_initializer\n",
    "from ocpmodels.models.gemnet_oc.interaction_indices import (\n",
    "    get_mixed_triplets,\n",
    "    get_quadruplets,\n",
    "    get_triplets,\n",
    ")\n",
    "from ocpmodels.models.gemnet_oc.layers.atom_update_block import OutputBlock\n",
    "from ocpmodels.models.gemnet_oc.layers.base_layers import Dense, ResidualLayer\n",
    "from ocpmodels.models.gemnet_oc.layers.efficient import BasisEmbedding\n",
    "from ocpmodels.models.gemnet_oc.layers.embedding_block import AtomEmbedding, EdgeEmbedding\n",
    "from ocpmodels.models.gemnet_oc.layers.force_scaler import ForceScaler\n",
    "from ocpmodels.models.gemnet_oc.layers.interaction_block import InteractionBlock\n",
    "from ocpmodels.models.gemnet_oc.layers.radial_basis import RadialBasis\n",
    "from ocpmodels.models.gemnet_oc.layers.spherical_basis import CircularBasisLayer, SphericalBasisLayer\n",
    "from ocpmodels.models.gemnet_oc.utils import (\n",
    "    get_angle,\n",
    "    get_edge_id,\n",
    "    get_inner_idx,\n",
    "    inner_product_clamped,\n",
    "    mask_neighbors,\n",
    "    repeat_blocks,\n",
    ")\n",
    "from ocpmodels.trainers import ForcesTrainer\n",
    "from ocpmodels import models\n",
    "from ocpmodels.models.gemnet_oc.gemnet_oc import GemNetOC"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@registry.register_model('Transfer_Gem')\n",
    "class Transfer_Gem(GemNetOC):\n",
    "    \"\"\"\n",
    "    Arguments\n",
    "    ---------\n",
    "    num_atoms (int): Unused argument\n",
    "    bond_feat_dim (int): Unused argument\n",
    "    num_targets: int\n",
    "        Number of prediction targets.\n",
    "\n",
    "    num_spherical: int\n",
    "        Controls maximum frequency.\n",
    "    num_radial: int\n",
    "        Controls maximum frequency.\n",
    "    num_blocks: int\n",
    "        Number of building blocks to be stacked.\n",
    "\n",
    "    emb_size_atom: int\n",
    "        Embedding size of the atoms.\n",
    "    emb_size_edge: int\n",
    "        Embedding size of the edges.\n",
    "    emb_size_trip_in: int\n",
    "        (Down-projected) embedding size of the quadruplet edge embeddings\n",
    "        before the bilinear layer.\n",
    "    emb_size_trip_out: int\n",
    "        (Down-projected) embedding size of the quadruplet edge embeddings\n",
    "        after the bilinear layer.\n",
    "    emb_size_quad_in: int\n",
    "        (Down-projected) embedding size of the quadruplet edge embeddings\n",
    "        before the bilinear layer.\n",
    "    emb_size_quad_out: int\n",
    "        (Down-projected) embedding size of the quadruplet edge embeddings\n",
    "        after the bilinear layer.\n",
    "    emb_size_aint_in: int\n",
    "        Embedding size in the atom interaction before the bilinear layer.\n",
    "    emb_size_aint_out: int\n",
    "        Embedding size in the atom interaction after the bilinear layer.\n",
    "    emb_size_rbf: int\n",
    "        Embedding size of the radial basis transformation.\n",
    "    emb_size_cbf: int\n",
    "        Embedding size of the circular basis transformation (one angle).\n",
    "    emb_size_sbf: int\n",
    "        Embedding size of the spherical basis transformation (two angles).\n",
    "\n",
    "    num_before_skip: int\n",
    "        Number of residual blocks before the first skip connection.\n",
    "    num_after_skip: int\n",
    "        Number of residual blocks after the first skip connection.\n",
    "    num_concat: int\n",
    "        Number of residual blocks after the concatenation.\n",
    "    num_atom: int\n",
    "        Number of residual blocks in the atom embedding blocks.\n",
    "    num_output_afteratom: int\n",
    "        Number of residual blocks in the output blocks\n",
    "        after adding the atom embedding.\n",
    "    num_atom_emb_layers: int\n",
    "        Number of residual blocks for transforming atom embeddings.\n",
    "    num_global_out_layers: int\n",
    "        Number of final residual blocks before the output.\n",
    "\n",
    "    regress_forces: bool\n",
    "        Whether to predict forces. Default: True\n",
    "    direct_forces: bool\n",
    "        If True predict forces based on aggregation of interatomic directions.\n",
    "        If False predict forces based on negative gradient of energy potential.\n",
    "    use_pbc: bool\n",
    "        Whether to use periodic boundary conditions.\n",
    "    scale_backprop_forces: bool\n",
    "        Whether to scale up the energy and then scales down the forces\n",
    "        to prevent NaNs and infs in backpropagated forces.\n",
    "\n",
    "    cutoff: float\n",
    "        Embedding cutoff for interatomic connections and embeddings in Angstrom.\n",
    "    cutoff_qint: float\n",
    "        Quadruplet interaction cutoff in Angstrom.\n",
    "        Optional. Uses cutoff per default.\n",
    "    cutoff_aeaint: float\n",
    "        Edge-to-atom and atom-to-edge interaction cutoff in Angstrom.\n",
    "        Optional. Uses cutoff per default.\n",
    "    cutoff_aint: float\n",
    "        Atom-to-atom interaction cutoff in Angstrom.\n",
    "        Optional. Uses maximum of all other cutoffs per default.\n",
    "    max_neighbors: int\n",
    "        Maximum number of neighbors for interatomic connections and embeddings.\n",
    "    max_neighbors_qint: int\n",
    "        Maximum number of quadruplet interactions per embedding.\n",
    "        Optional. Uses max_neighbors per default.\n",
    "    max_neighbors_aeaint: int\n",
    "        Maximum number of edge-to-atom and atom-to-edge interactions per embedding.\n",
    "        Optional. Uses max_neighbors per default.\n",
    "    max_neighbors_aint: int\n",
    "        Maximum number of atom-to-atom interactions per atom.\n",
    "        Optional. Uses maximum of all other neighbors per default.\n",
    "    enforce_max_neighbors_strictly: bool\n",
    "        When subselected edges based on max_neighbors args, arbitrarily\n",
    "        select amongst degenerate edges to have exactly the correct number.\n",
    "    rbf: dict\n",
    "        Name and hyperparameters of the radial basis function.\n",
    "    rbf_spherical: dict\n",
    "        Name and hyperparameters of the radial basis function used as part of the\n",
    "        circular and spherical bases.\n",
    "        Optional. Uses rbf per default.\n",
    "    envelope: dict\n",
    "        Name and hyperparameters of the envelope function.\n",
    "    cbf: dict\n",
    "        Name and hyperparameters of the circular basis function.\n",
    "    sbf: dict\n",
    "        Name and hyperparameters of the spherical basis function.\n",
    "    extensive: bool\n",
    "        Whether the output should be extensive (proportional to the number of atoms)\n",
    "    forces_coupled: bool\n",
    "        If True, enforce that |F_st| = |F_ts|. No effect if direct_forces is False.\n",
    "    output_init: str\n",
    "        Initialization method for the final dense layer.\n",
    "    activation: str\n",
    "        Name of the activation function.\n",
    "    scale_file: str\n",
    "        Path to the pytorch file containing the scaling factors.\n",
    "\n",
    "    quad_interaction: bool\n",
    "        Whether to use quadruplet interactions (with dihedral angles)\n",
    "    atom_edge_interaction: bool\n",
    "        Whether to use atom-to-edge interactions\n",
    "    edge_atom_interaction: bool\n",
    "        Whether to use edge-to-atom interactions\n",
    "    atom_interaction: bool\n",
    "        Whether to use atom-to-atom interactions\n",
    "\n",
    "    scale_basis: bool\n",
    "        Whether to use a scaling layer in the raw basis function for better\n",
    "        numerical stability.\n",
    "    qint_tags: list\n",
    "        Which atom tags to use quadruplet interactions for.\n",
    "        0=sub-surface bulk, 1=surface, 2=adsorbate atoms.\n",
    "    latent: bool\n",
    "        Decide if output the latent space or not.\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_atoms: Optional[int],\n",
    "        bond_feat_dim: int,\n",
    "        num_targets: int,\n",
    "        num_spherical=7,\n",
    "        num_radial=128,\n",
    "        num_blocks=4,\n",
    "        emb_size_atom=256,\n",
    "        emb_size_edge=512,\n",
    "        emb_size_trip_in=64,\n",
    "        emb_size_trip_out=64,\n",
    "        emb_size_quad_in=32,\n",
    "        emb_size_quad_out=32,\n",
    "        emb_size_aint_in=64,\n",
    "        emb_size_aint_out=64,\n",
    "        emb_size_rbf=16,\n",
    "        emb_size_cbf=16,\n",
    "        emb_size_sbf=32,\n",
    "        num_before_skip=2,\n",
    "        num_after_skip=2,\n",
    "        num_concat=1,\n",
    "        num_atom=3,\n",
    "        num_output_afteratom=3,\n",
    "        num_atom_emb_layers = 0,\n",
    "        num_global_out_layers = 2,\n",
    "        regress_forces = True,\n",
    "        direct_forces = False,\n",
    "        use_pbc = True,\n",
    "        scale_backprop_forces = False,\n",
    "        cutoff = 12.0,\n",
    "        cutoff_qint = 12.0,\n",
    "        cutoff_aeaint = 12.0,\n",
    "        cutoff_aint = 12.0,\n",
    "        max_neighbors = 30,\n",
    "        max_neighbors_qint =8,\n",
    "        max_neighbors_aeaint =20,\n",
    "        max_neighbors_aint = 1000,\n",
    "        enforce_max_neighbors_strictly = True,\n",
    "        rbf = {\"name\": \"gaussian\"},\n",
    "        rbf_spherical = None,\n",
    "        envelope = {\"name\": \"polynomial\", \"exponent\": 5},\n",
    "        cbf = {\"name\": \"spherical_harmonics\"},\n",
    "        sbf = {\"name\": \"spherical_harmonics\"},\n",
    "        extensive = True,\n",
    "        forces_coupled = False,\n",
    "        output_init = \"HeOrthogonal\",\n",
    "        activation = \"silu\",\n",
    "        quad_interaction = True,\n",
    "        atom_edge_interaction = True,\n",
    "        edge_atom_interaction = True,\n",
    "        atom_interaction = True,\n",
    "        scale_basis = False,\n",
    "        qint_tags = [1, 2],\n",
    "        num_elements = 83,\n",
    "        otf_graph = True,\n",
    "        scale_file = None,\n",
    "        latent: bool = True,\n",
    "        **kwargs,  # backwards compatibility with deprecated arguments\n",
    "    ):\n",
    "        super().__init__(\n",
    "                        num_atoms,\n",
    "                        bond_feat_dim,\n",
    "                        num_targets,\n",
    "                        num_spherical=7,\n",
    "                        num_radial=128,\n",
    "                        num_blocks=4,\n",
    "                        emb_size_atom=256,\n",
    "                        emb_size_edge=512,\n",
    "                        emb_size_trip_in=64,\n",
    "                        emb_size_trip_out=64,\n",
    "                        emb_size_quad_in=32,\n",
    "                        emb_size_quad_out=32,\n",
    "                        emb_size_aint_in=64,\n",
    "                        emb_size_aint_out=64,\n",
    "                        emb_size_rbf=16,\n",
    "                        emb_size_cbf=16,\n",
    "                        emb_size_sbf=32,\n",
    "                        num_before_skip=2,\n",
    "                        num_after_skip=2,\n",
    "                        num_concat=1,\n",
    "                        num_atom=3,\n",
    "                        num_output_afteratom=3,\n",
    "                        num_atom_emb_layers = 0,\n",
    "                        num_global_out_layers = 2,\n",
    "                        regress_forces = True,\n",
    "                        direct_forces = False,\n",
    "                        use_pbc = True,\n",
    "                        scale_backprop_forces = False,\n",
    "                        cutoff = 12.0,\n",
    "                        cutoff_qint = 12.0,\n",
    "                        cutoff_aeaint = 12.0,\n",
    "                        cutoff_aint = 12.0,\n",
    "                        max_neighbors = 30,\n",
    "                        max_neighbors_qint =8,\n",
    "                        max_neighbors_aeaint =20,\n",
    "                        max_neighbors_aint = 1000,\n",
    "                        enforce_max_neighbors_strictly = True,\n",
    "                        rbf = {\"name\": \"gaussian\"},\n",
    "                        rbf_spherical = None,\n",
    "                        envelope = {\"name\": \"polynomial\", \"exponent\": 5},\n",
    "                        cbf = {\"name\": \"spherical_harmonics\"},\n",
    "                        sbf = {\"name\": \"spherical_harmonics\"},\n",
    "                        extensive = True,\n",
    "                        forces_coupled = False,\n",
    "                        output_init = \"HeOrthogonal\",\n",
    "                        activation = \"silu\",\n",
    "                        quad_interaction = True,\n",
    "                        atom_edge_interaction = True,\n",
    "                        edge_atom_interaction = True,\n",
    "                        atom_interaction = True,\n",
    "                        scale_basis = False,\n",
    "                        qint_tags = [1, 2],\n",
    "                        num_elements = 83,\n",
    "                        otf_graph = True,\n",
    "                        scale_file = None,\n",
    "                        latent = True,\n",
    "                        )\n",
    "        \n",
    "        self.latent=latent\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    def forward(self, data):\n",
    "        pos = data.pos\n",
    "        batch = data.batch\n",
    "        atomic_numbers = data.atomic_numbers.long()\n",
    "        num_atoms = atomic_numbers.shape[0]\n",
    "        \n",
    "\n",
    "        if self.regress_forces and not self.direct_forces:\n",
    "            pos.requires_grad_(True)\n",
    "\n",
    "        (\n",
    "            main_graph,\n",
    "            a2a_graph,\n",
    "            a2ee2a_graph,\n",
    "            qint_graph,\n",
    "            id_swap,\n",
    "            trip_idx_e2e,\n",
    "            trip_idx_a2e,\n",
    "            trip_idx_e2a,\n",
    "            quad_idx,\n",
    "        ) = self.get_graphs_and_indices(data)\n",
    "        # print('checkpoint1')\n",
    "        _, idx_t = main_graph[\"edge_index\"]\n",
    "\n",
    "        (\n",
    "            basis_rad_raw,\n",
    "            basis_atom_update,\n",
    "            basis_output,\n",
    "            bases_qint,\n",
    "            bases_e2e,\n",
    "            bases_a2e,\n",
    "            bases_e2a,\n",
    "            basis_a2a_rad,\n",
    "        ) = self.get_bases(\n",
    "            main_graph=main_graph,\n",
    "            a2a_graph=a2a_graph,\n",
    "            a2ee2a_graph=a2ee2a_graph,\n",
    "            qint_graph=qint_graph,\n",
    "            trip_idx_e2e=trip_idx_e2e,\n",
    "            trip_idx_a2e=trip_idx_a2e,\n",
    "            trip_idx_e2a=trip_idx_e2a,\n",
    "            quad_idx=quad_idx,\n",
    "            num_atoms=num_atoms,\n",
    "        )\n",
    "        # print('checkpoint2')\n",
    "\n",
    "        # Embedding block\n",
    "        h = self.atom_emb(atomic_numbers)\n",
    "        # (nAtoms, emb_size_atom)\n",
    "        m = self.edge_emb(h, basis_rad_raw, main_graph[\"edge_index\"])\n",
    "        # (nEdges, emb_size_edge)\n",
    "\n",
    "        x_E, x_F = self.out_blocks[0](h, m, basis_output, idx_t)\n",
    "        # print(x_E.shape)\n",
    "        xs_E, xs_F = [x_E], [x_F]\n",
    "        # (nAtoms, num_targets), (nEdges, num_targets)\n",
    "        for i in range(self.num_blocks):\n",
    "            # Interaction block\n",
    "            h, m = self.int_blocks[i](\n",
    "                h=h,\n",
    "                m=m,\n",
    "                bases_qint=bases_qint,\n",
    "                bases_e2e=bases_e2e,\n",
    "                bases_a2e=bases_a2e,\n",
    "                bases_e2a=bases_e2a,\n",
    "                basis_a2a_rad=basis_a2a_rad,\n",
    "                basis_atom_update=basis_atom_update,\n",
    "                edge_index_main=main_graph[\"edge_index\"],\n",
    "                a2ee2a_graph=a2ee2a_graph,\n",
    "                a2a_graph=a2a_graph,\n",
    "                id_swap=id_swap,\n",
    "                trip_idx_e2e=trip_idx_e2e,\n",
    "                trip_idx_a2e=trip_idx_a2e,\n",
    "                trip_idx_e2a=trip_idx_e2a,\n",
    "                quad_idx=quad_idx,\n",
    "            )  # (nAtoms, emb_size_atom), (nEdges, emb_size_edge)\n",
    "\n",
    "            x_E, x_F = self.out_blocks[i + 1](h, m, basis_output, idx_t)\n",
    "            # (nAtoms, emb_size_atom), (nEdges, emb_size_edge)\n",
    "            xs_E.append(x_E)\n",
    "            xs_F.append(x_F)\n",
    "\n",
    "        # Implementing attention across pretrained blocks\n",
    "        E_all = torch.stack(xs_E, dim=0)\n",
    "#-----------------------------------------------------------------------------------------------------------------------------\n",
    "        # if self.add_positional_embedding:\n",
    "        #     E_all = self.MHA_positional_embedding(E_all)\n",
    "\n",
    "        # if self.attn_type == \"base\":\n",
    "\n",
    "        #     alpha = torch.bmm(E_all, torch.transpose(E_all, 1, 2))\n",
    "        #     alpha = alpha / math.sqrt(E_all.shape[-1])\n",
    "        #     alpha = self.softmax(alpha)\n",
    "\n",
    "        #     E_t = torch.bmm(alpha, E_all)\n",
    "        #     E_t = torch.sum(E_t, dim=0)\n",
    "\n",
    "        # elif self.attn_type == \"multi\":\n",
    "\n",
    "        #     q = self.lin_query_MHA(E_all)\n",
    "        #     k = self.lin_key_MHA(E_all)\n",
    "        #     v = self.lin_value_MHA(E_all)\n",
    "\n",
    "        #     E_t, w = self.MHA(q, k, v)\n",
    "        #     E_t = torch.sum(E_t, dim=0)\n",
    "\n",
    "        # if self.attn_type != \"base\":\n",
    "        #     E_t = self.out_energy(E_t)\n",
    "#----------------------------------------------need modified----attempt1-----------------------------------------------------------------\n",
    "        # if self.freeze:\n",
    "        #     for i in range(self.after_freeze_numblocks):\n",
    "        #         h, m = self.int_blocks[i](\n",
    "        #         h=h,\n",
    "        #         m=m,\n",
    "        #         bases_qint=bases_qint,\n",
    "        #         bases_e2e=bases_e2e,\n",
    "        #         bases_a2e=bases_a2e,\n",
    "        #         bases_e2a=bases_e2a,\n",
    "        #         basis_a2a_rad=basis_a2a_rad,\n",
    "        #         basis_atom_update=basis_atom_update,\n",
    "        #         edge_index_main=main_graph[\"edge_index\"],\n",
    "        #         a2ee2a_graph=a2ee2a_graph,\n",
    "        #         a2a_graph=a2a_graph,\n",
    "        #         id_swap=id_swap,\n",
    "        #         trip_idx_e2e=trip_idx_e2e,\n",
    "        #         trip_idx_a2e=trip_idx_a2e,\n",
    "        #         trip_idx_e2a=trip_idx_e2a,\n",
    "        #         quad_idx=quad_idx,\n",
    "        #     )  # (nAtoms, emb_size_atom), (nEdges, emb_size_edge)\n",
    "\n",
    "        #     x_E, x_F = self.out_blocks[i + 1](h, m, basis_output, idx_t)\n",
    "        #     # (nAtoms, emb_size_atom), (nEdges, emb_size_edge)\n",
    "        #     xs_E.append(x_E)\n",
    "        #     xs_F.append(x_F)\n",
    "        if self.latent:\n",
    "            # print('checkpoint3')\n",
    "            return E_all\n",
    "        else:\n",
    "#-----------------------------------------------------------------------------------------------------------------------------                \n",
    "            nMolecules = torch.max(batch) + 1\n",
    "            if self.extensive:\n",
    "                E_t = scatter_det(\n",
    "                    E_t, batch, dim=0, dim_size=nMolecules, reduce=\"add\"\n",
    "                )  # (nMolecules, num_targets)\n",
    "            else:\n",
    "                E_t = scatter_det(\n",
    "                    E_t, batch, dim=0, dim_size=nMolecules, reduce=\"mean\"\n",
    "                )  # (nMolecules, num_targets)\n",
    "\n",
    "            if self.regress_forces:\n",
    "                if self.direct_forces:\n",
    "                    if self.forces_coupled:  # enforce F_st = F_ts\n",
    "                        nEdges = idx_t.shape[0]\n",
    "                        id_undir = repeat_blocks(\n",
    "                            main_graph[\"num_neighbors\"] // 2,\n",
    "                            repeats=2,\n",
    "                            continuous_indexing=True,\n",
    "                        )\n",
    "                        F_st = scatter_det(\n",
    "                            F_st,\n",
    "                            id_undir,\n",
    "                            dim=0,\n",
    "                            dim_size=int(nEdges / 2),\n",
    "                            reduce=\"mean\",\n",
    "                        )  # (nEdges/2, num_targets)\n",
    "                        F_st = F_st[id_undir]  # (nEdges, num_targets)\n",
    "\n",
    "                    # map forces in edge directions\n",
    "                    F_st_vec = F_st[:, :, None] * main_graph[\"vector\"][:, None, :]\n",
    "                    # (nEdges, num_targets, 3)\n",
    "                    F_t = scatter_det(\n",
    "                        F_st_vec,\n",
    "                        idx_t,\n",
    "                        dim=0,\n",
    "                        dim_size=num_atoms,\n",
    "                        reduce=\"add\",\n",
    "                    )  # (nAtoms, num_targets, 3)\n",
    "                else:\n",
    "                    F_t = self.force_scaler.calc_forces_and_update(E_t, pos)\n",
    "\n",
    "                E_t = E_t.squeeze(1)  # (num_molecules)\n",
    "                F_t = F_t.squeeze(1)  # (num_atoms, 3)\n",
    "                return E_t, F_t\n",
    "            else:\n",
    "                E_t = E_t.squeeze(1)  # (num_molecules)\n",
    "                return E_t\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate transformer data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Unrecognized arguments: ['latent']\n",
      "c:\\Users\\lhuang37\\.conda\\envs\\ocp-models\\lib\\site-packages\\torch\\nn\\init.py:405: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n"
     ]
    }
   ],
   "source": [
    "myGemnet=Transfer_Gem(0,0,0,latent='True')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_path='params/gemnet_oc_base_oc20_oc22.pt'\n",
    "pretrained_state_dict = torch.load(checkpoint_path)\n",
    "new_model_state_dict = myGemnet.state_dict()\n",
    "filtered_pretrained_state_dict = {k: v for k, v in pretrained_state_dict.items() if k in new_model_state_dict}\n",
    "new_model_state_dict.update(filtered_pretrained_state_dict)\n",
    "myGemnet.load_state_dict(new_model_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lmdb\n",
    "import pickle\n",
    "def generate_lmdb(data, pathname: str):\n",
    "    \"\"\"\n",
    "    atoms_list:: Can be either a list of atoms objects or list of Data objects\n",
    "    \"\"\"\n",
    "    pathname = pathname + '.lmdb' if '.lmdb' not in pathname else pathname\n",
    "    db = lmdb.open(\n",
    "        pathname,\n",
    "        map_size=1099511627 * 3,\n",
    "        subdir=False,\n",
    "        meminit=False,\n",
    "        map_async=True,\n",
    "    ) \n",
    "    txn = db.begin(write=True)        \n",
    "    length=txn.stat()['entries']        \n",
    "    txn.put(f\"{length}\".encode('ascii'), pickle.dumps(data, protocol=0))\n",
    "    txn.commit()\n",
    "    db.sync()\n",
    "    db.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lmdb\n",
    "import pickle\n",
    "def lmdb_add_info(data, pathname: str):\n",
    "    \"\"\"\n",
    "    atoms_list:: Can be either a list of atoms objects or list of Data objects\n",
    "    \"\"\"\n",
    "    pathname = pathname + '.lmdb' if '.lmdb' not in pathname else pathname\n",
    "    db = lmdb.open(\n",
    "        pathname,\n",
    "        map_size=1099511626 * 3,\n",
    "        subdir=False,\n",
    "        meminit=False,\n",
    "        map_async=True,\n",
    "    ) \n",
    "    del data.edge_index\n",
    "    del data.cell_offsets\n",
    "    txn = db.begin(write=True)        \n",
    "    length=txn.stat()['entries']        \n",
    "    txn.put(f\"{length}\".encode('ascii'), pickle.dumps(data, protocol=0))\n",
    "    txn.commit()\n",
    "    db.sync()\n",
    "    db.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE='cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def out_fn(dataloader,model,pathname):\n",
    "\n",
    "    model.eval()    \n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:            \n",
    "            data=data.to(DEVICE)  \n",
    "            model=model.to(DEVICE) \n",
    "            output=model(data)\n",
    "            data=data.cpu()\n",
    "            data.latent=output.cpu()\n",
    "            del data.edge_index\n",
    "            del data.cell_offsets\n",
    "            lmdb_add_info(data,pathname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 2790], pos=[58, 3], cell=[1, 3, 3], atomic_numbers=[58], natoms=58, fixed=[58], tags=[58], nads=1, y_relaxed=-1.8839389085769653, pos_relaxed=[58, 3], sid=82967, id='0_85', oc22=1, cell_offsets=[2790, 3])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset=LmdbDataset({\"src\":\"Data/eoh.lmdb\"})\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lhuang37\\.conda\\envs\\ocp-models\\lib\\site-packages\\torch_geometric\\deprecation.py:12: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "import torch_geometric.data as geom_data\n",
    "node_data_loader = geom_data.DataLoader(dataset, batch_size=16)\n",
    "sv_path='Data/eoh_c.lmdb'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "MapFullError",
     "evalue": "mdb_put: MDB_MAP_FULL: Environment mapsize limit reached",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMapFullError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\lhuang37\\Desktop\\Shell_trans\\Shell_repo\\pre_process.ipynb Cell 13\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/lhuang37/Desktop/Shell_trans/Shell_repo/pre_process.ipynb#X15sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m out_fn(node_data_loader,myGemnet,sv_path)\n",
      "\u001b[1;32mc:\\Users\\lhuang37\\Desktop\\Shell_trans\\Shell_repo\\pre_process.ipynb Cell 13\u001b[0m in \u001b[0;36mout_fn\u001b[1;34m(dataloader, model, pathname)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lhuang37/Desktop/Shell_trans/Shell_repo/pre_process.ipynb#X15sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mdel\u001b[39;00m data\u001b[39m.\u001b[39medge_index\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lhuang37/Desktop/Shell_trans/Shell_repo/pre_process.ipynb#X15sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mdel\u001b[39;00m data\u001b[39m.\u001b[39mcell_offsets\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/lhuang37/Desktop/Shell_trans/Shell_repo/pre_process.ipynb#X15sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m lmdb_add_info(data,pathname)\n",
      "\u001b[1;32mc:\\Users\\lhuang37\\Desktop\\Shell_trans\\Shell_repo\\pre_process.ipynb Cell 13\u001b[0m in \u001b[0;36mlmdb_add_info\u001b[1;34m(data, pathname)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lhuang37/Desktop/Shell_trans/Shell_repo/pre_process.ipynb#X15sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m txn \u001b[39m=\u001b[39m db\u001b[39m.\u001b[39mbegin(write\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)        \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lhuang37/Desktop/Shell_trans/Shell_repo/pre_process.ipynb#X15sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m length\u001b[39m=\u001b[39mtxn\u001b[39m.\u001b[39mstat()[\u001b[39m'\u001b[39m\u001b[39mentries\u001b[39m\u001b[39m'\u001b[39m]        \n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/lhuang37/Desktop/Shell_trans/Shell_repo/pre_process.ipynb#X15sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m txn\u001b[39m.\u001b[39;49mput(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00mlength\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49mencode(\u001b[39m'\u001b[39;49m\u001b[39mascii\u001b[39;49m\u001b[39m'\u001b[39;49m), pickle\u001b[39m.\u001b[39;49mdumps(data, protocol\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lhuang37/Desktop/Shell_trans/Shell_repo/pre_process.ipynb#X15sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m txn\u001b[39m.\u001b[39mcommit()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lhuang37/Desktop/Shell_trans/Shell_repo/pre_process.ipynb#X15sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m db\u001b[39m.\u001b[39msync()\n",
      "\u001b[1;31mMapFullError\u001b[0m: mdb_put: MDB_MAP_FULL: Environment mapsize limit reached"
     ]
    }
   ],
   "source": [
    "out_fn(node_data_loader,myGemnet,sv_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useless now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = {\n",
    "  \"dataset\": \"oc22_lmdb\",\n",
    "  \"description\": \"Regressing to energies and forces for DFT trajectories from OCP\",\n",
    "  \"type\": \"regression\",\n",
    "  \"metric\": \"mae\",\n",
    "  \"labels\":\"potential energy\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model={'name':'gemne',\n",
    "  'num_spherical': 7,\n",
    "  'num_radial': 128,\n",
    "  'num_blocks': 4,\n",
    "  'emb_size_atom': 256,\n",
    "  'emb_size_edge': 512,\n",
    "  'emb_size_trip_in': 64,\n",
    "  'emb_size_trip_out': 64,\n",
    "  'mb_size_quad_in': 32,\n",
    "  'emb_size_quad_out': 32,\n",
    "  'emb_size_aint_in': 64,\n",
    "  'emb_size_aint_out': 64,\n",
    "  'emb_size_rbf': 16,\n",
    "  'emb_size_cbf': 16,\n",
    "  'emb_size_sbf': 32,\n",
    "  'num_before_skip': 2,\n",
    "  'num_after_skip': 2,\n",
    "  'num_concat': 1,\n",
    "  'num_atom': 3,\n",
    "  'num_output_afteratom': 3,\n",
    "  'cutoff': 12.0,\n",
    "  'cutoff_qint': 12.0,\n",
    "  'cutoff_aeaint': 12.0,\n",
    "  'cutoff_aint': 12.0,\n",
    "  'max_neighbors': 30,\n",
    "  'max_neighbors_qint': 8,\n",
    "  'max_neighbors_aeaint': 20,\n",
    "  'max_neighbors_aint': 1000,\n",
    "  'rbf':\n",
    "      {'name': 'gaussian'},\n",
    "  'envelope':\n",
    "      {'name': 'polynomial',\n",
    "    'exponent': 5},\n",
    "  'cbf':\n",
    "      {'name': 'spherical_harmonics'},\n",
    "  'sbf':\n",
    "      {'name': 'legendre_outer'},\n",
    "  'extensive': True,\n",
    "  'output_init': 'HeOrthogonal',\n",
    "  'activation': 'silu',\n",
    "  'regress_forces': True,\n",
    "  'direct_forces': True,\n",
    "  'forces_coupled': False,\n",
    "  'otf_graph': True,\n",
    "  'quad_interaction': True,\n",
    "  'atom_edge_interaction': True,\n",
    "  'edge_atom_interaction': True,\n",
    "  'atom_interaction': True,\n",
    "  'num_atom_emb_layers': 2,\n",
    "  'num_global_out_layers': 2,\n",
    "  'qint_tags': [1, 2]\n",
    "  #'latent':True    \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = {\n",
    "  'batch_size': 16,\n",
    "  'eval_batch_size': 16,\n",
    "  'load_balancing': 'atoms',\n",
    "  'eval_every': 5000,\n",
    "  'num_workers': 2,\n",
    "  'lr_initial': 5.e-4,\n",
    "  'optimizer': 'AdamW',\n",
    "  'optimizer_params': {\"amsgrad\": True},\n",
    "  'scheduler': 'ReduceLROnPlateau',\n",
    "  'mode': min,\n",
    "  'factor': 0.8,\n",
    "  'patience': 3,\n",
    "  'max_epochs': 80,\n",
    "  'ema_decay': 0.999,\n",
    "  'clip_grad_norm': 10,\n",
    "  'weight_decay': 0,  # 2e-6 (TF weight decay) / 1e-4 (lr) = 2e-2\n",
    "  'loss_energy': 'mae',\n",
    "  'loss_force': 'atomwisel2',\n",
    "  'force_coefficient': 1,\n",
    "  'energy_coefficient': 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = [\n",
    "  {'src': 'Data/bulk_val.lmdb'},\n",
    "  {'src': 'Data/bulk_val.lmdb'} # val set (optional)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = ForcesTrainer(\n",
    "    task=task,\n",
    "    model=model, # copied for later use, not necessary in practice.\n",
    "    dataset=dataset,\n",
    "    optimizer=optimizer,\n",
    "    identifier=\"S2EF-example\",\n",
    "    run_dir=\"./\", # directory to save results if is_debug=False. Prediction files are saved here so be careful not to override!\n",
    "    is_debug=False, # if True, do not save checkpoint, logs, or results\n",
    "    logger='tensorboard',\n",
    "    print_every=5,\n",
    "    seed=0, # random seed to use\n",
    "     # logger of choice (tensorboard and wandb supported)\n",
    "    local_rank=0,\n",
    "    amp=True, # use PyTorch Automatic Mixed Precision (faster training and less memory usage),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ocpmodels.trainers import ForcesTrainer\n",
    "from ocpmodels.datasets import TrajectoryLmdbDataset\n",
    "from ocpmodels import models\n",
    "from ocpmodels.common import logger\n",
    "from ocpmodels.common.utils import setup_logging\n",
    "setup_logging()\n",
    "\n",
    "import numpy as np\n",
    "import copy\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rectangle:\n",
    "    def __init__(self, length, width):\n",
    "        self.length = length\n",
    "        self.width = width\n",
    "\n",
    "    def area(self):\n",
    "        return self.length * self.width\n",
    "\n",
    "    def perimeter(self):\n",
    "        return 2 * self.length + 2 * self.width\n",
    "\n",
    "# Here we declare that the Square class inherits from the Rectangle class\n",
    "class Square(Rectangle):\n",
    "    def __init__(self, length,width,height):        \n",
    "        super().__init__(length,width)\n",
    "        self.height=height\n",
    "    def vol(self,):\n",
    "        return self.height*2+self.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffa=Square(7,6,height=2)\n",
    "ffa.vol()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_src='Data/bulk_train.lmdb'\n",
    "val_src='Data/bulk_train.lmdb'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
