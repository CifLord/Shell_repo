{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Standard libraries\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "import numpy as np \n",
    "import time\n",
    "\n",
    "## Imports for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('svg', 'pdf') # For export\n",
    "from matplotlib.colors import to_rgb\n",
    "import matplotlib\n",
    "matplotlib.rcParams['lines.linewidth'] = 2.0\n",
    "import seaborn as sns\n",
    "sns.reset_orig()\n",
    "sns.set()\n",
    "\n",
    "## Progress bar\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "## PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim\n",
    "# Torchvision\n",
    "import torchvision\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GATlayer(nn.Module):\n",
    "\n",
    "    def __init__(self,c_in,c_out, num_heads=1,concat_heads=True,alpha=0.2) -> None:\n",
    "        '''Inputs:\n",
    "                c_in: input feature dimension\n",
    "                c_out: output feature dimension\n",
    "                num_heads: the output features are equally split up over the heads if concat_heads=True\n",
    "                concat_heads: the output of the different heads is concatenated instaed of averaged\n",
    "                alpha:negative slpoe of the leakyReLU activation\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.num_heads=num_heads\n",
    "        self.concat_heads=concat_heads\n",
    "        if self.concat_heads:\n",
    "            assert c_out % num_heads ==0,\"num of output features must be a multiple of the count of heads\"\n",
    "            c_out=c_out//num_heads\n",
    "        self.projection=nn.Linear(c_in,c_out*num_heads)\n",
    "        self.a=nn.parameter(torch.Tensor(num_heads,2*c_out))\n",
    "        self.leakyrelu=nn.LeakyReLU(alpha)\n",
    "\n",
    "        nn.init.xavier_uniform_(self.projection.weight.data,gain=1.414)\n",
    "        nn.init.xavier_uniform_(self.a.data,gain=1.414)\n",
    "\n",
    "    def forward(self,node_feats,adj_matrix,print_attn_probs=False):\n",
    "        '''Inputs:\n",
    "                node_feats: Input features of the node, shape:[batch_size,c_in]\n",
    "                adj_matrix: adjacency matrix including self-connections. shape:[batch_size, num_nodes, num_nodes]\n",
    "                print_attn_probs:\n",
    "                '''\n",
    "        \n",
    "        batch_size, num_nodes = node_feats.size(0),node_feats.size(1)\n",
    "\n",
    "        node_feats = self.projection(node_feats)\n",
    "        node_feats = node_feats.view(batch_size, num_nodes, self.num_heads, -1)\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ocp-models",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
